{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1e7571c",
   "metadata": {},
   "source": [
    "# Llama Stack Inference Guide\n",
    "\n",
    "This document provides instructions on how to use Llama Stack's `chat_completion` function for generating text using the `Llama3.1-8B-Instruct` model. \n",
    "\n",
    "Before you begin, please ensure Llama Stack is installed and set up by following the [Getting Started Guide](https://llama-stack.readthedocs.io/en/latest/getting_started/index.html).\n",
    "\n",
    "\n",
    "### Table of Contents\n",
    "1. [Quickstart](#quickstart)\n",
    "2. [Building Effective Prompts](#building-effective-prompts)\n",
    "3. [Conversation Loop](#conversation-loop)\n",
    "4. [Conversation History](#conversation-history)\n",
    "5. [Streaming Responses](#streaming-responses)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414301dc",
   "metadata": {},
   "source": [
    "## Quickstart\n",
    "\n",
    "This section walks through each step to set up and make a simple text generation request.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b97dfe",
   "metadata": {},
   "source": [
    "### 0. Configuration\n",
    "Set up your connection parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38a39e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "HOST = \"localhost\"  # Replace with your host\n",
    "PORT = 8321       # Replace with your port\n",
    "# MODEL_NAME='meta-llama/Llama-3.2-3B-Instruct'\n",
    "MODEL_NAME=\"deepseek-ai/DeepSeek-R1-Distill-Qwen-14B\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dacaa2d-94e9-42e9-82a0-73522dfc7010",
   "metadata": {},
   "source": [
    "### 1. Set Up the Client\n",
    "\n",
    "Begin by importing the necessary components from Llama Stackâ€™s client library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a573752",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_stack_client import LlamaStackClient\n",
    "\n",
    "client = LlamaStackClient(base_url=f'http://{HOST}:{PORT}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86366383",
   "metadata": {},
   "source": [
    "### 2. Create a Chat Completion Request\n",
    "\n",
    "Use the `chat_completion` function to define the conversation context. Each message you include should have a specific role and content:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77c29dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, so I need to write a two-sentence poem about llamas. Hmm, where do I start? I know llamas are animals, they're from South America, maybe the Andes region. They look kind of like camels but smaller, with those distinctive faces and long eyelashes. I remember they have soft fur, which makes them nice to touch. Llamas are often used as pack animals, carrying loads for people. They're also known for their gentle nature, though sometimes they can be a bit mischievous.\n",
      "\n",
      "I should think about what makes llamas unique. Their appearance is striking, with that camel-like shape but smaller size. Their fur comes in various colors, which adds to their charm. Maybe I can mention their eyes or expressions, as they seem to have a certain look that's both curious and calm. Also, their behavior, like how they interact with humans or other animals, could be a good point to include.\n",
      "\n",
      "For the first sentence, I want to capture their essence. Maybe something about their presence or how they stand out in a landscape. The second sentence could highlight their personality or a specific trait, like their gentle nature or how they carry loads. I should use imagery that's vivid but concise since it's only two sentences.\n",
      "\n",
      "Let me try to structure it. The first line could describe their appearance or habitat, and the second line could talk about their characteristics or actions. I need to make sure the lines flow well and have a nice rhythm, even if it's not a strict rhyme scheme. Maybe using alliteration or assonance could help with the poetic feel.\n",
      "\n",
      "Wait, I should also consider the meter. Each sentence should have a similar number of syllables to create a balanced feel. Let me count the syllables in my initial thoughts. \"Llamas with soft fur and gentle eyes\" is 8 syllables. \"Roam the high Andes, carrying calm in their stride.\" That's 10 syllables. Close enough, I think. It gives a nice flow without being too forced.\n",
      "\n",
      "I think that works. The first line introduces their physical features, and the second line places them in their natural habitat while highlighting their gentle nature through their movement. It's concise and captures both their appearance and personality.\n",
      "</think>\n",
      "\n",
      "Llamas with soft fur and gentle eyes,  \n",
      "Roam the high Andes, carrying calm in their stride.\n"
     ]
    }
   ],
   "source": [
    "response = client.inference.chat_completion(\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a friendly assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Write a two-sentence poem about llama.\"}\n",
    "    ],\n",
    "    model_id=MODEL_NAME,\n",
    ")\n",
    "\n",
    "print(response.completion_message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f16949",
   "metadata": {},
   "source": [
    "## Building Effective Prompts\n",
    "\n",
    "Effective prompt creation (often called 'prompt engineering') is essential for quality responses. Here are best practices for structuring your prompts to get the most out of the Llama Stack model:\n",
    "\n",
    "### Sample Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c6812da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, so I need to write a two-sentence poem about llamas. Hmm, where do I start? I know llamas are animals, they're from South America, right? They have that camel-like appearance but smaller. They're often used for their wool, I think. Also, they have a sort of gentle demeanor, but I've heard they can be a bit spitty too. \n",
      "\n",
      "First, I should think about the imagery. Maybe describe their appearance. They have soft fur, maybe in different colors. Their eyes are big and expressive. They graze on grass, so maybe include that. \n",
      "\n",
      "For the second sentence, I can talk about their behavior or something unique about them. They're social animals, so maybe mention herds. Also, they have a calm presence, which people appreciate. Maybe something about their gentle nature or how they interact with humans.\n",
      "\n",
      "Putting it together, the first line could describe their appearance and the environment they're in. The second line could highlight their behavior or what they bring to that environment. I should make sure it flows well and has a nice rhythm.\n",
      "\n",
      "Wait, maybe I can use some alliteration or rhyme. Let me try that. \"Soft fur, gentle gaze\" sounds nice. Then, \"roam the meadows, never astray.\" That rhymes and gives a sense of their movement. \n",
      "\n",
      "For the second line, \"With coats of many hues,\" which describes their varied colors. Then, \"llamas bring calm to every view.\" That ties in their presence and the effect they have on the surroundings. \n",
      "\n",
      "Does that make sense? It captures their appearance, their gentle nature, and their role in the landscape. I think that works. I'll go with that.\n",
      "</think>\n",
      "\n",
      "Soft fur, gentle gaze, they roam the meadows, never astray.  \n",
      "With coats of many hues, llamas bring calm to every view.\n"
     ]
    }
   ],
   "source": [
    "response = client.inference.chat_completion(\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are shakespeare.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Write a two-sentence poem about llama.\"}\n",
    "    ],\n",
    "    model_id=MODEL_NAME,  # Changed from model to model_id\n",
    ")\n",
    "print(response.completion_message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8690ef0",
   "metadata": {},
   "source": [
    "## Conversation Loop\n",
    "\n",
    "To create a continuous conversation loop, where users can input multiple messages in a session, use the following structure. This example runs an asynchronous loop, ending when the user types 'exit,' 'quit,' or 'bye.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02211625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User>  quit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mEnding conversation. Goodbye!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from llama_stack_client import LlamaStackClient\n",
    "from termcolor import cprint\n",
    "\n",
    "client = LlamaStackClient(base_url=f'http://{HOST}:{PORT}')\n",
    "\n",
    "async def chat_loop():\n",
    "    while True:\n",
    "        user_input = input('User> ')\n",
    "        if user_input.lower() in ['exit', 'quit', 'bye']:\n",
    "            cprint('Ending conversation. Goodbye!', 'yellow')\n",
    "            break\n",
    "\n",
    "        message = {\"role\": \"user\", \"content\": user_input}\n",
    "        response = client.inference.chat_completion(\n",
    "            messages=[message],\n",
    "            model_id=MODEL_NAME\n",
    "        )\n",
    "        cprint(f'> Response: {response.completion_message.content}', 'cyan')\n",
    "\n",
    "# Run the chat loop in a Jupyter Notebook cell using await\n",
    "await chat_loop()\n",
    "# To run it in a python file, use this line instead\n",
    "# asyncio.run(chat_loop())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf0d555",
   "metadata": {},
   "source": [
    "## Conversation History\n",
    "\n",
    "Maintaining a conversation history allows the model to retain context from previous interactions. Use a list to accumulate messages, enabling continuity throughout the chat session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9496f75c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User>  bye\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mEnding conversation. Goodbye!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "async def chat_loop():\n",
    "    conversation_history = []\n",
    "    while True:\n",
    "        user_input = input('User> ')\n",
    "        if user_input.lower() in ['exit', 'quit', 'bye']:\n",
    "            cprint('Ending conversation. Goodbye!', 'yellow')\n",
    "            break\n",
    "\n",
    "        user_message = {\"role\": \"user\", \"content\": user_input}\n",
    "        conversation_history.append(user_message)\n",
    "\n",
    "        response = client.inference.chat_completion(\n",
    "            messages=conversation_history,\n",
    "            model_id=MODEL_NAME,\n",
    "        )\n",
    "        cprint(f'> Response: {response.completion_message.content}', 'cyan')\n",
    "\n",
    "        # Append the assistant message with all required fields\n",
    "        assistant_message = {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": response.completion_message.content,\n",
    "            # Add any additional required fields here if necessary\n",
    "        }\n",
    "        conversation_history.append(assistant_message)\n",
    "\n",
    "# Use `await` in the Jupyter Notebook cell to call the function\n",
    "await chat_loop()\n",
    "# To run it in a python file, use this line instead\n",
    "# asyncio.run(chat_loop())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fcf5e0",
   "metadata": {},
   "source": [
    "## Streaming Responses\n",
    "\n",
    "Llama Stack offers a `stream` parameter in the `chat_completion` function, which allows partial responses to be returned progressively as they are generated. This can enhance user experience by providing immediate feedback without waiting for the entire response to be processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d119026e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mUser> Write me a 3 sentence poem about llama\u001b[0m\n",
      "\u001b[36mAssistant> \u001b[0m\u001b[33mOkay\u001b[0m\u001b[33m,\u001b[0m\u001b[33m so\u001b[0m\u001b[33m I\u001b[0m\u001b[33m need\u001b[0m\u001b[33m to\u001b[0m\u001b[33m write\u001b[0m\u001b[33m a\u001b[0m\u001b[33m three\u001b[0m\u001b[33m-s\u001b[0m\u001b[33mentence\u001b[0m\u001b[33m poem\u001b[0m\u001b[33m about\u001b[0m\u001b[33m ll\u001b[0m\u001b[33mamas\u001b[0m\u001b[33m.\u001b[0m\u001b[33m Hmm\u001b[0m\u001b[33m,\u001b[0m\u001b[33m where\u001b[0m\u001b[33m do\u001b[0m\u001b[33m I\u001b[0m\u001b[33m start\u001b[0m\u001b[33m?\u001b[0m\u001b[33m I\u001b[0m\u001b[33m know\u001b[0m\u001b[33m ll\u001b[0m\u001b[33mamas\u001b[0m\u001b[33m are\u001b[0m\u001b[33m animals\u001b[0m\u001b[33m,\u001b[0m\u001b[33m they\u001b[0m\u001b[33m're\u001b[0m\u001b[33m from\u001b[0m\u001b[33m South\u001b[0m\u001b[33m America\u001b[0m\u001b[33m,\u001b[0m\u001b[33m maybe\u001b[0m\u001b[33m the\u001b[0m\u001b[33m And\u001b[0m\u001b[33mes\u001b[0m\u001b[33m?\u001b[0m\u001b[33m They\u001b[0m\u001b[33m look\u001b[0m\u001b[33m kind\u001b[0m\u001b[33m of\u001b[0m\u001b[33m like\u001b[0m\u001b[33m cam\u001b[0m\u001b[33mels\u001b[0m\u001b[33m but\u001b[0m\u001b[33m smaller\u001b[0m\u001b[33m,\u001b[0m\u001b[33m with\u001b[0m\u001b[33m those\u001b[0m\u001b[33m distinctive\u001b[0m\u001b[33m faces\u001b[0m\u001b[33m and\u001b[0m\u001b[33m long\u001b[0m\u001b[33m eyel\u001b[0m\u001b[33mashes\u001b[0m\u001b[33m.\u001b[0m\u001b[33m I\u001b[0m\u001b[33m remember\u001b[0m\u001b[33m they\u001b[0m\u001b[33m have\u001b[0m\u001b[33m soft\u001b[0m\u001b[33m fur\u001b[0m\u001b[33m,\u001b[0m\u001b[33m which\u001b[0m\u001b[33m makes\u001b[0m\u001b[33m them\u001b[0m\u001b[33m nice\u001b[0m\u001b[33m to\u001b[0m\u001b[33m touch\u001b[0m\u001b[33m.\u001b[0m\u001b[33m L\u001b[0m\u001b[33mlam\u001b[0m\u001b[33mas\u001b[0m\u001b[33m are\u001b[0m\u001b[33m often\u001b[0m\u001b[33m used\u001b[0m\u001b[33m as\u001b[0m\u001b[33m pack\u001b[0m\u001b[33m animals\u001b[0m\u001b[33m,\u001b[0m\u001b[33m right\u001b[0m\u001b[33m?\u001b[0m\u001b[33m They\u001b[0m\u001b[33m carry\u001b[0m\u001b[33m things\u001b[0m\u001b[33m for\u001b[0m\u001b[33m people\u001b[0m\u001b[33m.\u001b[0m\u001b[33m Also\u001b[0m\u001b[33m,\u001b[0m\u001b[33m they\u001b[0m\u001b[33m're\u001b[0m\u001b[33m social\u001b[0m\u001b[33m animals\u001b[0m\u001b[33m,\u001b[0m\u001b[33m so\u001b[0m\u001b[33m they\u001b[0m\u001b[33m live\u001b[0m\u001b[33m in\u001b[0m\u001b[33m groups\u001b[0m\u001b[33m.\u001b[0m\u001b[33m \n",
      "\n",
      "\u001b[0m\u001b[33mI\u001b[0m\u001b[33m should\u001b[0m\u001b[33m think\u001b[0m\u001b[33m about\u001b[0m\u001b[33m what\u001b[0m\u001b[33m makes\u001b[0m\u001b[33m ll\u001b[0m\u001b[33mamas\u001b[0m\u001b[33m unique\u001b[0m\u001b[33m.\u001b[0m\u001b[33m Their\u001b[0m\u001b[33m gentle\u001b[0m\u001b[33m nature\u001b[0m\u001b[33m,\u001b[0m\u001b[33m maybe\u001b[0m\u001b[33m?\u001b[0m\u001b[33m They\u001b[0m\u001b[33m're\u001b[0m\u001b[33m calm\u001b[0m\u001b[33m and\u001b[0m\u001b[33m can\u001b[0m\u001b[33m be\u001b[0m\u001b[33m friendly\u001b[0m\u001b[33m.\u001b[0m\u001b[33m Oh\u001b[0m\u001b[33m,\u001b[0m\u001b[33m and\u001b[0m\u001b[33m they\u001b[0m\u001b[33m spit\u001b[0m\u001b[33m when\u001b[0m\u001b[33m they\u001b[0m\u001b[33m're\u001b[0m\u001b[33m annoyed\u001b[0m\u001b[33m,\u001b[0m\u001b[33m that\u001b[0m\u001b[33m's\u001b[0m\u001b[33m a\u001b[0m\u001b[33m funny\u001b[0m\u001b[33m trait\u001b[0m\u001b[33m.\u001b[0m\u001b[33m Maybe\u001b[0m\u001b[33m I\u001b[0m\u001b[33m can\u001b[0m\u001b[33m include\u001b[0m\u001b[33m that\u001b[0m\u001b[33m.\u001b[0m\u001b[33m Also\u001b[0m\u001b[33m,\u001b[0m\u001b[33m their\u001b[0m\u001b[33m ears\u001b[0m\u001b[33m are\u001b[0m\u001b[33m long\u001b[0m\u001b[33m and\u001b[0m\u001b[33m kind\u001b[0m\u001b[33m of\u001b[0m\u001b[33m curved\u001b[0m\u001b[33m,\u001b[0m\u001b[33m like\u001b[0m\u001b[33m bananas\u001b[0m\u001b[33m.\u001b[0m\u001b[33m That\u001b[0m\u001b[33m's\u001b[0m\u001b[33m a\u001b[0m\u001b[33m cute\u001b[0m\u001b[33m image\u001b[0m\u001b[33m.\u001b[0m\u001b[33m \n",
      "\n",
      "\u001b[0m\u001b[33mNow\u001b[0m\u001b[33m,\u001b[0m\u001b[33m for\u001b[0m\u001b[33m the\u001b[0m\u001b[33m poem\u001b[0m\u001b[33m structure\u001b[0m\u001b[33m.\u001b[0m\u001b[33m Three\u001b[0m\u001b[33m sentences\u001b[0m\u001b[33m,\u001b[0m\u001b[33m so\u001b[0m\u001b[33m each\u001b[0m\u001b[33m should\u001b[0m\u001b[33m cover\u001b[0m\u001b[33m a\u001b[0m\u001b[33m different\u001b[0m\u001b[33m aspect\u001b[0m\u001b[33m.\u001b[0m\u001b[33m Maybe\u001b[0m\u001b[33m the\u001b[0m\u001b[33m first\u001b[0m\u001b[33m line\u001b[0m\u001b[33m introduces\u001b[0m\u001b[33m the\u001b[0m\u001b[33m llama\u001b[0m\u001b[33m's\u001b[0m\u001b[33m appearance\u001b[0m\u001b[33m,\u001b[0m\u001b[33m the\u001b[0m\u001b[33m second\u001b[0m\u001b[33m talks\u001b[0m\u001b[33m about\u001b[0m\u001b[33m their\u001b[0m\u001b[33m behavior\u001b[0m\u001b[33m or\u001b[0m\u001b[33m uses\u001b[0m\u001b[33m,\u001b[0m\u001b[33m and\u001b[0m\u001b[33m the\u001b[0m\u001b[33m third\u001b[0m\u001b[33m adds\u001b[0m\u001b[33m a\u001b[0m\u001b[33m touch\u001b[0m\u001b[33m of\u001b[0m\u001b[33m their\u001b[0m\u001b[33m personality\u001b[0m\u001b[33m or\u001b[0m\u001b[33m something\u001b[0m\u001b[33m unique\u001b[0m\u001b[33m.\u001b[0m\u001b[33m \n",
      "\n",
      "\u001b[0m\u001b[33mLet\u001b[0m\u001b[33m me\u001b[0m\u001b[33m try\u001b[0m\u001b[33m to\u001b[0m\u001b[33m form\u001b[0m\u001b[33m some\u001b[0m\u001b[33m lines\u001b[0m\u001b[33m.\u001b[0m\u001b[33m First\u001b[0m\u001b[33m line\u001b[0m\u001b[33m:\u001b[0m\u001b[33m \"\u001b[0m\u001b[33mIn\u001b[0m\u001b[33m the\u001b[0m\u001b[33m And\u001b[0m\u001b[33mean\u001b[0m\u001b[33m heights\u001b[0m\u001b[33m,\u001b[0m\u001b[33m where\u001b[0m\u001b[33m peaks\u001b[0m\u001b[33m touch\u001b[0m\u001b[33m the\u001b[0m\u001b[33m sky\u001b[0m\u001b[33m,\"\u001b[0m\u001b[33m that\u001b[0m\u001b[33m sets\u001b[0m\u001b[33m the\u001b[0m\u001b[33m scene\u001b[0m\u001b[33m.\u001b[0m\u001b[33m Then\u001b[0m\u001b[33m,\u001b[0m\u001b[33m \"\u001b[0m\u001b[33mll\u001b[0m\u001b[33mamas\u001b[0m\u001b[33m with\u001b[0m\u001b[33m soft\u001b[0m\u001b[33m coats\u001b[0m\u001b[33m and\u001b[0m\u001b[33m eyes\u001b[0m\u001b[33m that\u001b[0m\u001b[33m glow\u001b[0m\u001b[33m,\"\u001b[0m\u001b[33m describes\u001b[0m\u001b[33m their\u001b[0m\u001b[33m appearance\u001b[0m\u001b[33m.\u001b[0m\u001b[33m \n",
      "\n",
      "\u001b[0m\u001b[33mSecond\u001b[0m\u001b[33m line\u001b[0m\u001b[33m:\u001b[0m\u001b[33m Maybe\u001b[0m\u001b[33m something\u001b[0m\u001b[33m about\u001b[0m\u001b[33m their\u001b[0m\u001b[33m purpose\u001b[0m\u001b[33m,\u001b[0m\u001b[33m like\u001b[0m\u001b[33m carrying\u001b[0m\u001b[33m loads\u001b[0m\u001b[33m.\u001b[0m\u001b[33m \"\u001b[0m\u001b[33mThey\u001b[0m\u001b[33m carry\u001b[0m\u001b[33m the\u001b[0m\u001b[33m weight\u001b[0m\u001b[33m of\u001b[0m\u001b[33m woven\u001b[0m\u001b[33m loads\u001b[0m\u001b[33m,\"\u001b[0m\u001b[33m and\u001b[0m\u001b[33m add\u001b[0m\u001b[33m a\u001b[0m\u001b[33m rhyme\u001b[0m\u001b[33m,\u001b[0m\u001b[33m \"\u001b[0m\u001b[33mwith\u001b[0m\u001b[33m gentle\u001b[0m\u001b[33m,\u001b[0m\u001b[33m patient\u001b[0m\u001b[33m grace\u001b[0m\u001b[33m they\u001b[0m\u001b[33m go\u001b[0m\u001b[33m.\"\u001b[0m\u001b[33m \n",
      "\n",
      "\u001b[0m\u001b[33mThird\u001b[0m\u001b[33m line\u001b[0m\u001b[33m:\u001b[0m\u001b[33m Include\u001b[0m\u001b[33m their\u001b[0m\u001b[33m unique\u001b[0m\u001b[33m trait\u001b[0m\u001b[33m,\u001b[0m\u001b[33m like\u001b[0m\u001b[33m sp\u001b[0m\u001b[33mitting\u001b[0m\u001b[33m.\u001b[0m\u001b[33m \"\u001b[0m\u001b[33mWhen\u001b[0m\u001b[33m shadows\u001b[0m\u001b[33m stretch\u001b[0m\u001b[33m long\u001b[0m\u001b[33m and\u001b[0m\u001b[33m the\u001b[0m\u001b[33m sun\u001b[0m\u001b[33m dips\u001b[0m\u001b[33m low\u001b[0m\u001b[33m,\"\u001b[0m\u001b[33m and\u001b[0m\u001b[33m then\u001b[0m\u001b[33m \"\u001b[0m\u001b[33ma\u001b[0m\u001b[33m gentle\u001b[0m\u001b[33m spit\u001b[0m\u001b[33m or\u001b[0m\u001b[33m a\u001b[0m\u001b[33m playful\u001b[0m\u001b[33m blow\u001b[0m\u001b[33m.\"\u001b[0m\u001b[33m That\u001b[0m\u001b[33m adds\u001b[0m\u001b[33m a\u001b[0m\u001b[33m bit\u001b[0m\u001b[33m of\u001b[0m\u001b[33m their\u001b[0m\u001b[33m personality\u001b[0m\u001b[33m and\u001b[0m\u001b[33m a\u001b[0m\u001b[33m rhyme\u001b[0m\u001b[33m.\u001b[0m\u001b[33m \n",
      "\n",
      "\u001b[0m\u001b[33mPutting\u001b[0m\u001b[33m it\u001b[0m\u001b[33m all\u001b[0m\u001b[33m together\u001b[0m\u001b[33m,\u001b[0m\u001b[33m does\u001b[0m\u001b[33m it\u001b[0m\u001b[33m flow\u001b[0m\u001b[33m?\u001b[0m\u001b[33m Each\u001b[0m\u001b[33m line\u001b[0m\u001b[33m has\u001b[0m\u001b[33m a\u001b[0m\u001b[33m rhyme\u001b[0m\u001b[33m scheme\u001b[0m\u001b[33m,\u001b[0m\u001b[33m maybe\u001b[0m\u001b[33m AABB\u001b[0m\u001b[33m.\u001b[0m\u001b[33m Let\u001b[0m\u001b[33m me\u001b[0m\u001b[33m check\u001b[0m\u001b[33m the\u001b[0m\u001b[33m syll\u001b[0m\u001b[33mables\u001b[0m\u001b[33m.\u001b[0m\u001b[33m First\u001b[0m\u001b[33m line\u001b[0m\u001b[33m:\u001b[0m\u001b[33m \u001b[0m\u001b[33m8\u001b[0m\u001b[33m syll\u001b[0m\u001b[33mables\u001b[0m\u001b[33m.\u001b[0m\u001b[33m Second\u001b[0m\u001b[33m line\u001b[0m\u001b[33m:\u001b[0m\u001b[33m \u001b[0m\u001b[33m8\u001b[0m\u001b[33m.\u001b[0m\u001b[33m Third\u001b[0m\u001b[33m line\u001b[0m\u001b[33m:\u001b[0m\u001b[33m \u001b[0m\u001b[33m8\u001b[0m\u001b[33m.\u001b[0m\u001b[33m So\u001b[0m\u001b[33m it\u001b[0m\u001b[33m's\u001b[0m\u001b[33m consistent\u001b[0m\u001b[33m.\u001b[0m\u001b[33m \n",
      "\n",
      "\u001b[0m\u001b[33mI\u001b[0m\u001b[33m think\u001b[0m\u001b[33m that\u001b[0m\u001b[33m works\u001b[0m\u001b[33m.\u001b[0m\u001b[33m It\u001b[0m\u001b[33m captures\u001b[0m\u001b[33m their\u001b[0m\u001b[33m environment\u001b[0m\u001b[33m,\u001b[0m\u001b[33m appearance\u001b[0m\u001b[33m,\u001b[0m\u001b[33m and\u001b[0m\u001b[33m a\u001b[0m\u001b[33m bit\u001b[0m\u001b[33m of\u001b[0m\u001b[33m their\u001b[0m\u001b[33m behavior\u001b[0m\u001b[33m.\u001b[0m\u001b[33m Hopefully\u001b[0m\u001b[33m,\u001b[0m\u001b[33m it\u001b[0m\u001b[33m's\u001b[0m\u001b[33m a\u001b[0m\u001b[33m nice\u001b[0m\u001b[33m little\u001b[0m\u001b[33m poem\u001b[0m\u001b[33m about\u001b[0m\u001b[33m ll\u001b[0m\u001b[33mamas\u001b[0m\u001b[33m.\n",
      "\u001b[0m\u001b[33m</think>\u001b[0m\u001b[33m\n",
      "\n",
      "\u001b[0m\u001b[33mIn\u001b[0m\u001b[33m the\u001b[0m\u001b[33m And\u001b[0m\u001b[33mean\u001b[0m\u001b[33m heights\u001b[0m\u001b[33m,\u001b[0m\u001b[33m where\u001b[0m\u001b[33m peaks\u001b[0m\u001b[33m touch\u001b[0m\u001b[33m the\u001b[0m\u001b[33m sky\u001b[0m\u001b[33m,\u001b[0m\u001b[33m  \n",
      "\u001b[0m\u001b[33mll\u001b[0m\u001b[33mamas\u001b[0m\u001b[33m with\u001b[0m\u001b[33m soft\u001b[0m\u001b[33m coats\u001b[0m\u001b[33m and\u001b[0m\u001b[33m eyes\u001b[0m\u001b[33m that\u001b[0m\u001b[33m glow\u001b[0m\u001b[33m,\u001b[0m\u001b[33m  \n",
      "\u001b[0m\u001b[33mthey\u001b[0m\u001b[33m carry\u001b[0m\u001b[33m the\u001b[0m\u001b[33m weight\u001b[0m\u001b[33m of\u001b[0m\u001b[33m woven\u001b[0m\u001b[33m loads\u001b[0m\u001b[33m,\u001b[0m\u001b[33m  \n",
      "\u001b[0m\u001b[33mwith\u001b[0m\u001b[33m gentle\u001b[0m\u001b[33m,\u001b[0m\u001b[33m patient\u001b[0m\u001b[33m grace\u001b[0m\u001b[33m they\u001b[0m\u001b[33m go\u001b[0m\u001b[33m.\u001b[0m\u001b[33m  \n",
      "\u001b[0m\u001b[33mWhen\u001b[0m\u001b[33m shadows\u001b[0m\u001b[33m stretch\u001b[0m\u001b[33m long\u001b[0m\u001b[33m and\u001b[0m\u001b[33m the\u001b[0m\u001b[33m sun\u001b[0m\u001b[33m dips\u001b[0m\u001b[33m low\u001b[0m\u001b[33m,\u001b[0m\u001b[33m  \n",
      "\u001b[0m\u001b[33ma\u001b[0m\u001b[33m gentle\u001b[0m\u001b[33m spit\u001b[0m\u001b[33m or\u001b[0m\u001b[33m a\u001b[0m\u001b[33m playful\u001b[0m\u001b[33m blow\u001b[0m\u001b[33m.\u001b[0m\u001b[97m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from llama_stack_client.lib.inference.event_logger import EventLogger\n",
    "\n",
    "async def run_main(stream: bool = True):\n",
    "    client = LlamaStackClient(base_url=f'http://{HOST}:{PORT}')\n",
    "\n",
    "    message = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": 'Write me a 3 sentence poem about llama'\n",
    "    }\n",
    "    cprint(f'User> {message[\"content\"]}', 'green')\n",
    "\n",
    "    response = client.inference.chat_completion(\n",
    "        messages=[message],\n",
    "        model_id=MODEL_NAME,\n",
    "        stream=stream,\n",
    "    )\n",
    "\n",
    "    if not stream:\n",
    "        cprint(f'> Response: {response.completion_message.content}', 'cyan')\n",
    "    else:\n",
    "        for log in EventLogger().log(response):\n",
    "            log.print()\n",
    "\n",
    "# In a Jupyter Notebook cell, use `await` to call the function\n",
    "await run_main()\n",
    "# To run it in a python file, use this line instead\n",
    "# asyncio.run(run_main())\n"
   ]
  }
 ],
 "metadata": {
  "fileHeader": "",
  "fileUid": "7da25939-a2a3-463c-958e-9cdfd710d158",
  "isAdHoc": false,
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
